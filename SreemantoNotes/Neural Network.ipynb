{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the mnist dataset\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size=0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      5\n",
       "1      0\n",
       "2      4\n",
       "3      1\n",
       "4      9\n",
       "...   ..\n",
       "69995  2\n",
       "69996  3\n",
       "69997  4\n",
       "69998  5\n",
       "69999  6\n",
       "\n",
       "[70000 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 39900.52, NNZs: 609, Bias: -147.000000, T: 56000, Avg. loss: 47829.281071\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 50430.95, NNZs: 625, Bias: -258.000000, T: 112000, Avg. loss: 41871.517589\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 55342.64, NNZs: 631, Bias: -349.000000, T: 168000, Avg. loss: 40644.481268\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 61330.70, NNZs: 638, Bias: -437.000000, T: 224000, Avg. loss: 39691.584964\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 65872.07, NNZs: 639, Bias: -519.000000, T: 280000, Avg. loss: 37451.551268\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 70270.47, NNZs: 641, Bias: -599.000000, T: 336000, Avg. loss: 38000.861607\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 75737.63, NNZs: 642, Bias: -688.000000, T: 392000, Avg. loss: 37473.104982\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 78739.64, NNZs: 645, Bias: -769.000000, T: 448000, Avg. loss: 37771.096214\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 82426.77, NNZs: 645, Bias: -846.000000, T: 504000, Avg. loss: 37595.581607\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 84898.87, NNZs: 646, Bias: -931.000000, T: 560000, Avg. loss: 36655.403125\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 88048.11, NNZs: 646, Bias: -997.000000, T: 616000, Avg. loss: 37103.852643\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 90568.70, NNZs: 646, Bias: -1078.000000, T: 672000, Avg. loss: 35573.746804\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 92918.28, NNZs: 646, Bias: -1150.000000, T: 728000, Avg. loss: 37128.677179\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 96025.50, NNZs: 647, Bias: -1229.000000, T: 784000, Avg. loss: 35858.980768\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 98266.62, NNZs: 649, Bias: -1304.000000, T: 840000, Avg. loss: 35219.850982\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 100218.55, NNZs: 649, Bias: -1381.000000, T: 896000, Avg. loss: 36146.659357\n",
      "Total training time: 1.69 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 101695.76, NNZs: 649, Bias: -1448.000000, T: 952000, Avg. loss: 35072.258107\n",
      "Total training time: 1.76 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 103449.47, NNZs: 648, Bias: -1523.000000, T: 1008000, Avg. loss: 37552.684893\n",
      "Total training time: 1.89 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 105254.64, NNZs: 649, Bias: -1595.000000, T: 1064000, Avg. loss: 36086.208768\n",
      "Total training time: 1.98 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 106665.69, NNZs: 649, Bias: -1667.000000, T: 1120000, Avg. loss: 36287.896000\n",
      "Total training time: 2.06 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 108090.51, NNZs: 651, Bias: -1741.000000, T: 1176000, Avg. loss: 35721.914482\n",
      "Total training time: 2.16 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 108945.74, NNZs: 651, Bias: -1809.000000, T: 1232000, Avg. loss: 36318.300089\n",
      "Total training time: 2.25 seconds.\n",
      "Convergence after 22 epochs took 2.25 seconds\n",
      "-- Epoch 1\n",
      "Norm: 28681.98, NNZs: 579, Bias: -45.000000, T: 56000, Avg. loss: 27064.213321\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 37020.95, NNZs: 595, Bias: -68.000000, T: 112000, Avg. loss: 24173.044446\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 42219.99, NNZs: 612, Bias: -96.000000, T: 168000, Avg. loss: 23215.488893\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46192.43, NNZs: 618, Bias: -121.000000, T: 224000, Avg. loss: 22375.258304\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 48964.06, NNZs: 624, Bias: -138.000000, T: 280000, Avg. loss: 22635.797929\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 51396.14, NNZs: 625, Bias: -159.000000, T: 336000, Avg. loss: 22387.508536\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 55024.68, NNZs: 625, Bias: -166.000000, T: 392000, Avg. loss: 20814.417232\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 57393.48, NNZs: 627, Bias: -185.000000, T: 448000, Avg. loss: 21451.790839\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 61053.73, NNZs: 630, Bias: -198.000000, T: 504000, Avg. loss: 20939.470357\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 63648.94, NNZs: 634, Bias: -214.000000, T: 560000, Avg. loss: 22064.327536\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 66458.16, NNZs: 638, Bias: -227.000000, T: 616000, Avg. loss: 21230.175929\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 68775.18, NNZs: 638, Bias: -242.000000, T: 672000, Avg. loss: 22135.623071\n",
      "Total training time: 1.11 seconds.\n",
      "Convergence after 12 epochs took 1.11 seconds\n",
      "-- Epoch 1\n",
      "Norm: 39327.26, NNZs: 638, Bias: -142.000000, T: 56000, Avg. loss: 101568.522375\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 47069.91, NNZs: 651, Bias: -262.000000, T: 112000, Avg. loss: 96126.469304\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 52982.63, NNZs: 656, Bias: -377.000000, T: 168000, Avg. loss: 95091.047125\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 56726.64, NNZs: 666, Bias: -479.000000, T: 224000, Avg. loss: 93747.490464\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 61942.92, NNZs: 671, Bias: -594.000000, T: 280000, Avg. loss: 93913.842464\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 66127.33, NNZs: 671, Bias: -713.000000, T: 336000, Avg. loss: 92461.013196\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 66951.96, NNZs: 670, Bias: -818.000000, T: 392000, Avg. loss: 93476.545143\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 69479.05, NNZs: 671, Bias: -917.000000, T: 448000, Avg. loss: 93393.855500\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 71204.29, NNZs: 671, Bias: -1018.000000, T: 504000, Avg. loss: 92845.381661\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 74391.83, NNZs: 671, Bias: -1120.000000, T: 560000, Avg. loss: 94317.037018\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 76232.61, NNZs: 671, Bias: -1219.000000, T: 616000, Avg. loss: 91079.953786\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 77255.50, NNZs: 672, Bias: -1320.000000, T: 672000, Avg. loss: 91642.749500\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 78255.62, NNZs: 673, Bias: -1417.000000, T: 728000, Avg. loss: 92953.259500\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 81676.63, NNZs: 678, Bias: -1514.000000, T: 784000, Avg. loss: 93668.609393\n",
      "Total training time: 1.28 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 83249.29, NNZs: 678, Bias: -1614.000000, T: 840000, Avg. loss: 93448.105821\n",
      "Total training time: 1.36 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 83665.75, NNZs: 678, Bias: -1713.000000, T: 896000, Avg. loss: 94035.486036\n",
      "Total training time: 1.44 seconds.\n",
      "Convergence after 16 epochs took 1.44 seconds\n",
      "-- Epoch 1\n",
      "Norm: 38585.33, NNZs: 609, Bias: -274.000000, T: 56000, Avg. loss: 124149.776357\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 46327.32, NNZs: 617, Bias: -499.000000, T: 112000, Avg. loss: 121713.571875\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 49656.86, NNZs: 625, Bias: -715.000000, T: 168000, Avg. loss: 119838.484375\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 55582.18, NNZs: 629, Bias: -929.000000, T: 224000, Avg. loss: 118995.129357\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 59566.18, NNZs: 629, Bias: -1147.000000, T: 280000, Avg. loss: 122832.309893\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 61311.56, NNZs: 633, Bias: -1351.000000, T: 336000, Avg. loss: 116533.473679\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 64755.31, NNZs: 635, Bias: -1578.000000, T: 392000, Avg. loss: 120095.666054\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 66237.96, NNZs: 635, Bias: -1795.000000, T: 448000, Avg. loss: 121881.118089\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 68923.11, NNZs: 635, Bias: -2013.000000, T: 504000, Avg. loss: 121028.421304\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 70634.41, NNZs: 635, Bias: -2230.000000, T: 560000, Avg. loss: 122118.868964\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 73593.01, NNZs: 635, Bias: -2456.000000, T: 616000, Avg. loss: 121884.648321\n",
      "Total training time: 0.96 seconds.\n",
      "Convergence after 11 epochs took 0.96 seconds\n",
      "-- Epoch 1\n",
      "Norm: 43133.12, NNZs: 635, Bias: -82.000000, T: 56000, Avg. loss: 68120.350429\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 51044.26, NNZs: 646, Bias: -153.000000, T: 112000, Avg. loss: 64026.907714\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 59101.12, NNZs: 652, Bias: -213.000000, T: 168000, Avg. loss: 63852.229000\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 64184.33, NNZs: 653, Bias: -266.000000, T: 224000, Avg. loss: 61382.109911\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 69352.37, NNZs: 654, Bias: -326.000000, T: 280000, Avg. loss: 61378.621161\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 73351.54, NNZs: 657, Bias: -383.000000, T: 336000, Avg. loss: 60664.236589\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 75723.13, NNZs: 661, Bias: -439.000000, T: 392000, Avg. loss: 60910.819786\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 79550.51, NNZs: 661, Bias: -475.000000, T: 448000, Avg. loss: 59567.063393\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 81898.13, NNZs: 660, Bias: -533.000000, T: 504000, Avg. loss: 60154.627357\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 85982.04, NNZs: 661, Bias: -582.000000, T: 560000, Avg. loss: 59250.419536\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 87906.30, NNZs: 662, Bias: -625.000000, T: 616000, Avg. loss: 61081.832518\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 90350.98, NNZs: 664, Bias: -675.000000, T: 672000, Avg. loss: 59452.249625\n",
      "Total training time: 1.28 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 92773.51, NNZs: 665, Bias: -718.000000, T: 728000, Avg. loss: 59619.087393\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 93898.34, NNZs: 665, Bias: -760.000000, T: 784000, Avg. loss: 58182.195018\n",
      "Total training time: 1.45 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 95713.82, NNZs: 665, Bias: -803.000000, T: 840000, Avg. loss: 59819.720554\n",
      "Total training time: 1.56 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 97450.50, NNZs: 665, Bias: -847.000000, T: 896000, Avg. loss: 59301.725821\n",
      "Total training time: 1.63 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 99306.76, NNZs: 665, Bias: -892.000000, T: 952000, Avg. loss: 59456.285804\n",
      "Total training time: 1.73 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 101490.33, NNZs: 668, Bias: -939.000000, T: 1008000, Avg. loss: 59525.100286\n",
      "Total training time: 1.83 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 103155.81, NNZs: 671, Bias: -978.000000, T: 1064000, Avg. loss: 58645.323554\n",
      "Total training time: 1.90 seconds.\n",
      "Convergence after 19 epochs took 1.90 seconds\n",
      "-- Epoch 1\n",
      "Norm: 46829.63, NNZs: 622, Bias: 60.000000, T: 56000, Avg. loss: 122387.544607\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 57205.61, NNZs: 632, Bias: 123.000000, T: 112000, Avg. loss: 113434.448054\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 64295.00, NNZs: 641, Bias: 182.000000, T: 168000, Avg. loss: 112993.095339\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 69083.80, NNZs: 641, Bias: 243.000000, T: 224000, Avg. loss: 113014.959411\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 73974.07, NNZs: 643, Bias: 305.000000, T: 280000, Avg. loss: 110700.960518\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 78828.34, NNZs: 645, Bias: 370.000000, T: 336000, Avg. loss: 110740.038714\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 82348.90, NNZs: 645, Bias: 438.000000, T: 392000, Avg. loss: 109271.827929\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 86805.66, NNZs: 646, Bias: 495.000000, T: 448000, Avg. loss: 108880.444839\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 88865.33, NNZs: 648, Bias: 567.000000, T: 504000, Avg. loss: 108383.994125\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 90716.20, NNZs: 648, Bias: 627.000000, T: 560000, Avg. loss: 108736.882768\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 93947.49, NNZs: 651, Bias: 698.000000, T: 616000, Avg. loss: 110618.516732\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 96126.22, NNZs: 651, Bias: 762.000000, T: 672000, Avg. loss: 110668.160357\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 99136.62, NNZs: 651, Bias: 827.000000, T: 728000, Avg. loss: 105971.486071\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 101624.83, NNZs: 652, Bias: 897.000000, T: 784000, Avg. loss: 106198.225071\n",
      "Total training time: 1.28 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 103928.93, NNZs: 651, Bias: 948.000000, T: 840000, Avg. loss: 107724.497482\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 105610.93, NNZs: 652, Bias: 995.000000, T: 896000, Avg. loss: 108761.691982\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 107316.14, NNZs: 653, Bias: 1058.000000, T: 952000, Avg. loss: 108447.006036\n",
      "Total training time: 1.56 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 108312.19, NNZs: 653, Bias: 1127.000000, T: 1008000, Avg. loss: 107204.043964\n",
      "Total training time: 1.65 seconds.\n",
      "Convergence after 18 epochs took 1.65 seconds\n",
      "-- Epoch 1\n",
      "Norm: 37564.52, NNZs: 592, Bias: -153.000000, T: 56000, Avg. loss: 61194.032214\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 44034.71, NNZs: 601, Bias: -282.000000, T: 112000, Avg. loss: 59090.256643\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 48231.66, NNZs: 612, Bias: -402.000000, T: 168000, Avg. loss: 56637.416018\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 54226.40, NNZs: 619, Bias: -520.000000, T: 224000, Avg. loss: 57763.077286\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 57647.36, NNZs: 622, Bias: -638.000000, T: 280000, Avg. loss: 57071.212625\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 61727.91, NNZs: 624, Bias: -756.000000, T: 336000, Avg. loss: 56440.685768\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 63491.33, NNZs: 624, Bias: -866.000000, T: 392000, Avg. loss: 56919.929036\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 66155.75, NNZs: 624, Bias: -979.000000, T: 448000, Avg. loss: 57566.528786\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 68320.93, NNZs: 624, Bias: -1096.000000, T: 504000, Avg. loss: 57146.389661\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 71189.42, NNZs: 624, Bias: -1222.000000, T: 560000, Avg. loss: 56181.414696\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 72751.38, NNZs: 624, Bias: -1337.000000, T: 616000, Avg. loss: 56804.108107\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 74505.18, NNZs: 625, Bias: -1448.000000, T: 672000, Avg. loss: 56362.662036\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 75465.83, NNZs: 625, Bias: -1562.000000, T: 728000, Avg. loss: 54731.633304\n",
      "Total training time: 1.27 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 77521.83, NNZs: 625, Bias: -1679.000000, T: 784000, Avg. loss: 55136.551429\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 79800.68, NNZs: 625, Bias: -1796.000000, T: 840000, Avg. loss: 55419.939714\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 81536.18, NNZs: 626, Bias: -1899.000000, T: 896000, Avg. loss: 56333.814714\n",
      "Total training time: 1.56 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 82785.87, NNZs: 626, Bias: -2007.000000, T: 952000, Avg. loss: 54789.394821\n",
      "Total training time: 1.67 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 83267.44, NNZs: 626, Bias: -2109.000000, T: 1008000, Avg. loss: 55435.460679\n",
      "Total training time: 1.77 seconds.\n",
      "Convergence after 18 epochs took 1.77 seconds\n",
      "-- Epoch 1\n",
      "Norm: 35032.89, NNZs: 602, Bias: -25.000000, T: 56000, Avg. loss: 61226.092750\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 40809.11, NNZs: 605, Bias: -49.000000, T: 112000, Avg. loss: 59019.986429\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 45661.48, NNZs: 614, Bias: -54.000000, T: 168000, Avg. loss: 58979.281036\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 49691.63, NNZs: 617, Bias: -80.000000, T: 224000, Avg. loss: 59112.373125\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 51726.20, NNZs: 624, Bias: -96.000000, T: 280000, Avg. loss: 57905.742946\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 54464.73, NNZs: 627, Bias: -118.000000, T: 336000, Avg. loss: 56943.062821\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 58581.07, NNZs: 632, Bias: -135.000000, T: 392000, Avg. loss: 58373.722500\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 61124.95, NNZs: 634, Bias: -150.000000, T: 448000, Avg. loss: 57922.851018\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 63183.67, NNZs: 634, Bias: -167.000000, T: 504000, Avg. loss: 58753.372411\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 64993.19, NNZs: 634, Bias: -192.000000, T: 560000, Avg. loss: 57323.698750\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 67099.62, NNZs: 634, Bias: -207.000000, T: 616000, Avg. loss: 56910.985750\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 68540.03, NNZs: 636, Bias: -223.000000, T: 672000, Avg. loss: 57059.384054\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 70117.47, NNZs: 636, Bias: -241.000000, T: 728000, Avg. loss: 57841.151946\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 72575.06, NNZs: 639, Bias: -244.000000, T: 784000, Avg. loss: 56938.592036\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 74065.38, NNZs: 639, Bias: -258.000000, T: 840000, Avg. loss: 57018.448536\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 75130.35, NNZs: 639, Bias: -271.000000, T: 896000, Avg. loss: 57285.091500\n",
      "Total training time: 1.36 seconds.\n",
      "Convergence after 16 epochs took 1.36 seconds\n",
      "-- Epoch 1\n",
      "Norm: 46961.66, NNZs: 624, Bias: -746.000000, T: 56000, Avg. loss: 236785.696625\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 52877.61, NNZs: 631, Bias: -1443.000000, T: 112000, Avg. loss: 237268.609214\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 59481.26, NNZs: 634, Bias: -2106.000000, T: 168000, Avg. loss: 235142.555589\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 63341.75, NNZs: 634, Bias: -2747.000000, T: 224000, Avg. loss: 233064.034786\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 66116.08, NNZs: 638, Bias: -3406.000000, T: 280000, Avg. loss: 233096.487804\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 68708.27, NNZs: 643, Bias: -4068.000000, T: 336000, Avg. loss: 237641.257018\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 71152.74, NNZs: 648, Bias: -4701.000000, T: 392000, Avg. loss: 234873.800964\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 73322.07, NNZs: 651, Bias: -5335.000000, T: 448000, Avg. loss: 230322.193857\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 75050.35, NNZs: 652, Bias: -5995.000000, T: 504000, Avg. loss: 235918.757286\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 76091.41, NNZs: 652, Bias: -6647.000000, T: 560000, Avg. loss: 235537.056000\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 78186.55, NNZs: 653, Bias: -7301.000000, T: 616000, Avg. loss: 232038.836679\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 80091.75, NNZs: 655, Bias: -7954.000000, T: 672000, Avg. loss: 235408.452214\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 82376.40, NNZs: 656, Bias: -8587.000000, T: 728000, Avg. loss: 233056.725893\n",
      "Total training time: 1.25 seconds.\n",
      "Convergence after 13 epochs took 1.25 seconds\n",
      "-- Epoch 1\n",
      "Norm: 41943.91, NNZs: 636, Bias: -335.000000, T: 56000, Avg. loss: 160581.586179\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 51582.87, NNZs: 644, Bias: -643.000000, T: 112000, Avg. loss: 157203.122089\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 56805.11, NNZs: 650, Bias: -916.000000, T: 168000, Avg. loss: 157590.440929\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 58943.53, NNZs: 653, Bias: -1211.000000, T: 224000, Avg. loss: 154532.398929\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 63600.98, NNZs: 653, Bias: -1493.000000, T: 280000, Avg. loss: 155216.294821\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 67529.60, NNZs: 656, Bias: -1783.000000, T: 336000, Avg. loss: 155001.888036\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 69112.39, NNZs: 659, Bias: -2053.000000, T: 392000, Avg. loss: 154523.003982\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 70895.51, NNZs: 661, Bias: -2336.000000, T: 448000, Avg. loss: 155081.606839\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 72690.92, NNZs: 664, Bias: -2624.000000, T: 504000, Avg. loss: 151485.828554\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 74713.34, NNZs: 668, Bias: -2913.000000, T: 560000, Avg. loss: 153009.984571\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 76134.96, NNZs: 669, Bias: -3197.000000, T: 616000, Avg. loss: 154231.601893\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 77918.82, NNZs: 669, Bias: -3468.000000, T: 672000, Avg. loss: 151346.992571\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 78711.70, NNZs: 669, Bias: -3741.000000, T: 728000, Avg. loss: 151020.819196\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 81677.37, NNZs: 669, Bias: -4023.000000, T: 784000, Avg. loss: 154516.950875\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 83032.92, NNZs: 669, Bias: -4303.000000, T: 840000, Avg. loss: 154409.029268\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 84403.55, NNZs: 669, Bias: -4571.000000, T: 896000, Avg. loss: 152728.623750\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 85960.56, NNZs: 669, Bias: -4854.000000, T: 952000, Avg. loss: 154485.025696\n",
      "Total training time: 1.54 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 86989.18, NNZs: 672, Bias: -5142.000000, T: 1008000, Avg. loss: 155036.268286\n",
      "Total training time: 1.62 seconds.\n",
      "Convergence after 18 epochs took 1.62 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   15.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(max_iter=30, random_state=1, tol=0.0001, verbose=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per = Perceptron(max_iter = 30, tol = 0.0001, random_state = 1, verbose=1)\n",
    "per.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions\n",
    "y_pred_train = per.predict(X_train)\n",
    "y_pred_test = per.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8886964285714286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8724285714285714"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(accuracy_score(Y_train,y_pred_train))\n",
    "accuracy_score(Y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  51., 159., 253., 159.,  50.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        48., 238., 252., 252., 252., 237.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  54., 227., 253., 252., 239., 233.,\n",
       "       252.,  57.,   6.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  10.,  60.,\n",
       "       224., 252., 253., 252., 202.,  84., 252., 253., 122.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0., 163., 252., 252., 252., 253., 252., 252.,\n",
       "        96., 189., 253., 167.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  51., 238.,\n",
       "       253., 253., 190., 114., 253., 228.,  47.,  79., 255., 168.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  48., 238., 252., 252., 179.,  12.,  75., 121.,\n",
       "        21.,   0.,   0., 253., 243.,  50.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  38., 165., 253.,\n",
       "       233., 208.,  84.,   0.,   0.,   0.,   0.,   0.,   0., 253., 252.,\n",
       "       165.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   7., 178., 252., 240.,  71.,  19.,  28.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0., 253., 252., 195.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  57., 252., 252.,\n",
       "        63.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 253.,\n",
       "       252., 195.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0., 198., 253., 190.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0., 255., 253., 196.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  76., 246., 252.,\n",
       "       112.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       253., 252., 148.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  85., 252., 230.,  25.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   7., 135., 253., 186.,  12.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  85., 252.,\n",
       "       223.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   7., 131.,\n",
       "       252., 225.,  71.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  85., 252., 145.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  48., 165., 252., 173.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  86.,\n",
       "       253., 225.,   0.,   0.,   0.,   0.,   0.,   0., 114., 238., 253.,\n",
       "       162.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  85., 252., 249., 146.,  48.,  29.,\n",
       "        85., 178., 225., 253., 223., 167.,  56.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        85., 252., 252., 252., 229., 215., 252., 252., 252., 196., 130.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  28., 199., 252., 252., 253.,\n",
       "       252., 252., 233., 145.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  25., 128., 252., 253., 252., 141.,  37.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=X[1]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=a.reshape(28,28).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22e6d1e5e88>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22e6d25d0c8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a=X[2]\n",
    "a=a.reshape(28,28).astype('uint8')\n",
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn=MLPClassifier(activation='logistic',solver='sgd',hidden_layer_sizes=(10,15),random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skesh\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(10, 15),\n",
       "              random_state=1, solver='sgd')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions\n",
    "y_pred_train = nn.predict(X_train)\n",
    "y_pred_test = nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8889821428571428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8773571428571428"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(accuracy_score(Y_train,y_pred_train))\n",
    "accuracy_score(Y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
